from functools import wraps
from aiohttp import web
import json
from ymicp import beian
import random
from datetime import datetime
import json
import asyncio
import aiohttp
import aiohttp_jinja2
import jinja2
import re
import sys
import os
import signal
from cachetools import TTLCache
from mlog import logger
from load_config import config
import subprocess
import uuid
import locale
import weakref
from database import Database
from collections import deque
import threading
import logging

VERSION="0.6.2"

pool_cache = TTLCache(maxsize=config.proxy.extra_api.pool_num, 
                      ttl=config.proxy.extra_api.timeout - config.proxy.extra_api.timeout_drop)

# å®æ—¶æ—¥å¿—æ”¶é›†å™¨
class LogCollector:
    def __init__(self, maxlen=1000):
        self.logs = deque(maxlen=maxlen)
        self.lock = threading.Lock()
    
    def add_log(self, message, level='INFO'):
        with self.lock:
            self.logs.append({
                'time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'message': message,
                'level': level
            })
    
    def get_logs(self, limit=500):
        with self.lock:
            logs_list = list(self.logs)
            return logs_list[-limit:] if len(logs_list) > limit else logs_list
    
    def clear(self):
        with self.lock:
            self.logs.clear()

# è‡ªå®šä¹‰æ—¥å¿—å¤„ç†å™¨ï¼Œå°†æ—¥å¿—æ·»åŠ åˆ°LogCollector
class CollectorHandler(logging.Handler):
    def __init__(self, collector):
        super().__init__()
        self.collector = collector
    
    def emit(self, record):
        try:
            msg = self.format(record)
            # è¿‡æ»¤æ‰aiohttp.accessçš„æ—¥å¿—ï¼Œå› ä¸ºå¤ªå¤šäº†
            if 'aiohttp.access' not in record.name:
                self.collector.add_log(msg, record.levelname)
        except Exception:
            self.handleError(record)

log_collector = LogCollector()

# å…¨å±€ä»»åŠ¡ç®¡ç†å™¨
class TaskManager:
    def __init__(self):
        self._tasks = weakref.WeakValueDictionary()
        self._semaphores = {}
        
    def add_task(self, task_name, task):
        self._tasks[task_name] = task
        
    def get_task(self, task_name):
        return self._tasks.get(task_name)
        
    def remove_task(self, task_name):
        if task_name in self._tasks:
            task = self._tasks[task_name]
            if not task.done():
                task.cancel()
            del self._tasks[task_name]
            
    def get_semaphore(self, name, limit):
        if name not in self._semaphores:
            self._semaphores[name] = asyncio.Semaphore(limit)
        return self._semaphores[name]

task_manager = TaskManager()

def signal_handler(sig, frame):
    if sig == signal.SIGINT:
        logger.warning('æ”¶åˆ°å…³é—­ä¿¡å·ï¼Œç¨‹åºåœæ­¢')
        # æ¸…ç†æ‰€æœ‰ä»»åŠ¡
        for task_name in list(task_manager._tasks.keys()):
            task_manager.remove_task(task_name)
        sys.exit()

signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)

def is_valid_url(url):
    regex = re.compile(
        r'^(?:http)s?://'  # http:// or https:// or ftp://
        r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\.)+(?:[A-Z]{2,6}\.?|[A-Z0-9-]{2,}\.?)|'  # domain...
        r'localhost|'  # localhost...
        r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}|'  # ...or ipv4
        r'\[?[A-F0-9]*:[A-F0-9:]+\]?)'  # ...or ipv6
        r'(?::\d+)?'  # optional port
        r'(?:/?|[/?]\S+)$', re.IGNORECASE)
    return re.match(regex, url) is not None

def get_resource_path(relative_path):
    """è·å–æ‰“åŒ…åçš„å¯æ‰§è¡Œæ–‡ä»¶ä¸­çš„èµ„æºæ–‡ä»¶è·¯å¾„"""
    if getattr(sys, 'frozen', False):  # å¦‚æœæ˜¯æ‰“åŒ…åçš„ç¨‹åº
        app_path = os.path.dirname(sys.executable)
    else:
        app_path = os.path.dirname(os.path.abspath(__file__))

    return os.path.join(app_path, relative_path)

# æ£€æŸ¥IPv6åœ°å€æ˜¯å¦ä¸ºå…¬ç½‘IP
def is_public_ipv6(ipv6):
    return not (ipv6.startswith("fe80") or ipv6.startswith("fc00") or ipv6.startswith("fd00"))

def _run_cmd_capture(cmd):
    """æ‰§è¡Œç³»ç»Ÿå‘½ä»¤å¹¶è‡ªåŠ¨å¤šç¼–ç å°è¯•è§£ç """
    try:
        p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        out, err = p.communicate(timeout=5)
    except Exception:
        return ""
    if not out:
        return ""
    enc_candidates = [
        "utf-8",
        locale.getpreferredencoding(False) or "",
        "gbk",
        "cp936",
        "latin-1",
    ]
    for enc in enc_candidates:
        if not enc:
            continue
        try:
            return out.decode(enc)
        except Exception:
            continue
    return out.decode("utf-8", errors="ignore")

# è·å–æœ¬åœ°IPv6åœ°å€
def get_local_ipv6_addresses():
    addresses = []
    try:
        if os.name == 'nt':
            output = _run_cmd_capture(["netsh", "interface", "ipv6", "show", "addresses"])
            if not output:
                return []
            for line in output.splitlines():
                line_strip = line.strip()
                if any(k in line_strip for k in ("å…¬ç”¨", "æ‰‹åŠ¨", "Public", "Manual")) and ":" in line_strip:
                    parts = line_strip.split()
                    candidate = parts[-1].split("/")[0]
                    if ":" in candidate and is_public_ipv6(candidate):
                        addresses.append(candidate)
        else:
            output = _run_cmd_capture(["ip", "-6", "addr", "show"])
            if not output:
                return []
            for line in output.splitlines():
                line_strip = line_strip = line.strip()
                if ("inet6" in line_strip) and ("scope global" in line_strip):
                    try:
                        candidate = line_strip.split()[1].split("/")[0]
                        if is_public_ipv6(candidate):
                            addresses.append(candidate)
                    except:
                        continue
    except Exception:
        return []
    return list(dict.fromkeys(addresses))

# é…ç½®æŒ‡å®šæ•°é‡çš„IPv6åœ°å€
def configure_ipv6_addresses(prefix, count, adapter_name):
    if os.name == 'nt':  # Windows
        for _ in range(count):
            guid = uuid.uuid4().hex
            new_temp_ipv6 = f"{prefix}:{guid[:4]}:{guid[4:8]}:{guid[8:12]}:{guid[12:16]}"
            subprocess.run([
                "netsh", "interface", "ipv6", "add", "address", adapter_name, new_temp_ipv6,
                "store=active", "skipassource=true"
            ], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    else:  # Linux
        for _ in range(count):
            guid = uuid.uuid4().hex
            new_temp_ipv6 = f"{prefix}:{guid[:4]}:{guid[4:8]}:{guid[8:12]}:{guid[12:16]}"
            subprocess.run([
                "ip", "-6", "addr", "add", new_temp_ipv6, "dev", adapter_name
            ], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

# åˆå§‹åŒ–IPv6åœ°å€æ± 
async def init_ipv6_pool(app):
    logger.info("å¯ç”¨æœ¬åœ°IPv6è½®è¯¢")
    local_ipv6_addresses = get_local_ipv6_addresses()
    public_ipv6_addresses = [addr for addr in local_ipv6_addresses if is_public_ipv6(addr)]
    if len(public_ipv6_addresses) < config.proxy.local_ipv6_pool.pool_num:
        prefix = ":".join(public_ipv6_addresses[0].split(":")[0:4])  # è·å–å‰å››ä½ä½œä¸ºå‰ç¼€
        configure_ipv6_addresses(prefix, config.proxy.local_ipv6_pool.pool_num - len(public_ipv6_addresses), config.proxy.local_ipv6_pool.ipv6_network_card)
        logger.info(f"å·²é…ç½® {config.proxy.local_ipv6_pool.pool_num - len(public_ipv6_addresses)} ä¸ªæ–°çš„IPv6åœ°å€")
    else:
        logger.info("å·²æœ‰è¶³å¤Ÿçš„IPv6åœ°å€ï¼Œæ— éœ€é…ç½®")
    asyncio.create_task(check_and_update_ipv6_pool())

async def check_and_update_ipv6_pool():
    while True:
        local_ipv6_addresses = get_local_ipv6_addresses()

        public_ipv6_addresses = [addr for addr in local_ipv6_addresses if is_public_ipv6(addr)]
        if len(public_ipv6_addresses) < config.proxy.local_ipv6_pool.pool_num:
            prefix = ":".join(public_ipv6_addresses[0].split(":")[0:4])  # è·å–å‰å››ä½ä½œä¸ºå‰ç¼€
            configure_ipv6_addresses(prefix, config.proxy.local_ipv6_pool.pool_num - len(public_ipv6_addresses), config.proxy.local_ipv6_pool.ipv6_network_card)
            logger.info(f"å·²è¡¥å…… {config.proxy.local_ipv6_pool.pool_num - len(public_ipv6_addresses)} ä¸ªæ–°çš„IPv6åœ°å€")
        await asyncio.sleep(config.proxy.local_ipv6_pool.check_interval)

# è·¨åŸŸå‚æ•°
corscode = {
    "Access-Control-Allow-Origin": "*",
    "Access-Control-Allow-Methods": "GET, POST, OPTIONS",  # éœ€è¦é™åˆ¶è¯·æ±‚å°±åœ¨è¿™é‡Œå¢åˆ 
    "Access-Control-Allow-Headers": "*",
    "Server": "are you ok?",
}

# å®ä¾‹åŒ–è·¯ç”±
routes = web.RouteTableDef()


class Pool:
    def __init__(self) -> None:
        # è·å–ä»£ç†åœ°å€çš„æ¥å£
        self.proxy_url = config.proxy.extra_api.url
        # ä»£ç†å‰©ä½™å¤šå°‘ç§’æ—¶ä¸¢å¼ƒ
        self.discard = config.proxy.extra_api.timeouut_drop
        # å¤šå°‘ç§’è·å–ä¸€æ¬¡ä»£ç†ï¼Œå½“å‰æ¥å£é™åˆ¶æå–é¢‘ç‡ä¸º1sï¼Œé€‚å½“è°ƒæ•´
        self.period = config.proxy.extra_api.extra_interval
        # ä»£ç†åœ°å€æ± åŒæ—¶å­˜åœ¨å¤šå°‘ä»£ç†
        self.number = config.proxy.extra_api.pool_num
        # ä»£ç†æ± çš„ç»Ÿä¸€session
        self.session = None
        # æ›´æ–°é”ï¼Œé˜²æ­¢å¹¶å‘æ›´æ–°
        self._update_lock = asyncio.Lock()
        # å¯åŠ¨å®šæ—¶ä»»åŠ¡ï¼Œç»´æŠ¤åœ°å€æ± 
        self._update_task = None
        
    async def start(self):
        """å¯åŠ¨ä»£ç†æ± ç»´æŠ¤ä»»åŠ¡"""
        if self._update_task is None:
            self._update_task = asyncio.create_task(self.cron_update())

    async def stop(self):
        """åœæ­¢ä»£ç†æ± ç»´æŠ¤ä»»åŠ¡"""
        if self._update_task:
            self._update_task.cancel()
            try:
                await self._update_task
            except asyncio.CancelledError:
                pass
        await self._close_session()

    async def cron_create(self):
        await self.start()

    async def _init_session(self):
        if self.session is None:
            timeout = aiohttp.ClientTimeout(total=config.system.http_client_timeout)
            self.session = aiohttp.ClientSession(timeout=timeout)

    async def _close_session(self):
        if self.session is not None:
            await self.session.close()
            self.session = None

    # è·å–æ–°çš„ä»£ç†åˆ°ä»£ç†åœ°å€æ± 
    async def _update(self):
        async with self._update_lock:
            if len(pool_cache) >= self.number:
                logger.info(f"ä»£ç†æ± é¥±æ»¡ï¼Œæ— éœ€æ›´æ–°ä»£ç†ï¼Œå½“å‰æ± å†…æ•°é‡ï¼š{len(pool_cache)}")
                return
                
            try:
                await self._init_session()
                async with self.session.get(self.proxy_url) as req:
                    res = await req.text()
                    proxy_list = [p.strip() for p in res.split("\n") if p.strip()]
                    
                    if len(proxy_list) == 0:
                        logger.error("æå–åˆ°çš„IPä¸º0")
                        return
                        
                    endtime = datetime.now().timestamp()
                    
                    if config.proxy.extra_api.check_proxy:
                        await self._check_and_add_proxies(proxy_list, endtime)
                    else:
                        for address in proxy_list:
                            if len(pool_cache) >= self.number:
                                break
                            pool_cache[address] = endtime
                            
                    logger.info(f"æ›´æ–°ä»£ç†æ± æˆåŠŸï¼Œå½“å‰ä»£ç†æ•°é‡ï¼š{len(pool_cache)}")
                    
            except Exception as e:
                logger.error(f"æ›´æ–°ä»£ç†æ± å¤±è´¥: {e}")

    async def _check_and_add_proxies(self, proxy_list, endtime):
        """å¹¶å‘æ£€æŸ¥ä»£ç†å¯ç”¨æ€§å¹¶æ·»åŠ åˆ°æ± ä¸­"""
        semaphore = asyncio.Semaphore(config.proxy.extra_api.check_proxy_num)
        
        async def check_proxy(address):
            async with semaphore:
                if len(pool_cache) >= self.number:
                    return
                    
                timeout = aiohttp.ClientTimeout(total=config.proxy.extra_api.proxy_timeout)
                try:
                    from aiohttp import TCPConnector
                    async with aiohttp.ClientSession(
                        timeout=timeout, connector=TCPConnector(ssl=False)
                    ) as session:
                        async with session.get(
                            "http://ifconfig.me/ip", proxy=f"http://{address}"
                        ) as req:
                            await req.text()
                    
                    if len(pool_cache) < self.number:
                        pool_cache[address] = endtime
                        logger.info(f"å…¥åº“ä»£ç†æˆåŠŸï¼š{address}")
                except Exception:
                    logger.info(f"å…¥åº“æ£€æµ‹ä»£ç†ä¸å¯ç”¨ï¼š{address}")

        # ä½¿ç”¨asyncio.gatherå¤„ç†å¹¶å‘ä»»åŠ¡ï¼Œæ·»åŠ å¼‚å¸¸å¤„ç†
        tasks = [check_proxy(address) for address in proxy_list]
        await asyncio.gather(*tasks, return_exceptions=True)

    # å®šæ—¶ä»»åŠ¡,æ›´æ–°åœ°å€æ± 
    async def cron_update(self):
        try:
            while True:
                await self._update()
                await asyncio.sleep(self.period)
        except asyncio.CancelledError:
            logger.info("ä»£ç†æ± æ›´æ–°ä»»åŠ¡å·²å–æ¶ˆ")
            raise

    async def getproxy(self, num=1):
        # ç­‰å¾…ä»£ç†æ± æœ‰å¯ç”¨ä»£ç†
        timeout = 30  # 30ç§’è¶…æ—¶
        start_time = asyncio.get_event_loop().time()
        
        while True:
            if len(pool_cache) != 0:
                break
            if asyncio.get_event_loop().time() - start_time > timeout:
                raise TimeoutError("ç­‰å¾…ä»£ç†è¶…æ—¶")
            await asyncio.sleep(0.1)
            
        random_key = f"http://{random.choice(list(pool_cache.keys()))}"
        return random_key

# å¼‚æ­¥jsonåºåˆ—åŒ–
def jsondump(func):
    @wraps(func)
    async def wrapper(*args, **kwargs):
        result = await func(*args, **kwargs)
        try:
            # è¿”å› web.Response å¯¹è±¡è€Œä¸æ˜¯çº¯å­—ç¬¦ä¸²
            json_text = json.dumps(result, ensure_ascii=False)
            return web.Response(
                text=json_text,
                content_type='application/json',
                charset='utf-8'
            )
        except Exception as e:
            logger.error(f"JSONåºåˆ—åŒ–å¤±è´¥: {e}, result: {result}")
            # å¦‚æœåºåˆ—åŒ–å¤±è´¥ï¼Œå°è¯•è¿”å›é”™è¯¯ä¿¡æ¯
            return web.Response(
                text=json.dumps({"code": 500, "message": f"JSONåºåˆ—åŒ–å¤±è´¥: {str(e)}"}, ensure_ascii=False),
                content_type='application/json',
                charset='utf-8'
            )

    return wrapper


# å°è£…ä¸€ä¸‹web.json_resp
wj = lambda *args, **kwargs: web.json_response(*args, **kwargs)


# å¤„ç†OPTIONSå’Œè·¨åŸŸçš„ä¸­é—´ä»¶
async def options_middleware(app, handler):
    async def middleware(request):
        # å¤„ç† OPTIONS è¯·æ±‚ï¼Œç›´æ¥è¿”å›ç©ºæ•°æ®å’Œå…è®¸è·¨åŸŸçš„ header
        if request.method == "OPTIONS":
            return wj(headers=corscode)

        # ç»§ç»­å¤„ç†å…¶ä»–è¯·æ±‚,åŒæ—¶å¤„ç†å¼‚å¸¸å“åº”ï¼Œè¿”å›æ­£å¸¸jsonå€¼æˆ–è‡ªå®šä¹‰é¡µé¢
        try:
            response = await handler(request)
            # ç¡®ä¿responseæ˜¯Responseå¯¹è±¡å†æ›´æ–°headers
            if hasattr(response, 'headers'):
                response.headers.update(corscode)
                return response
            elif not hasattr(response, 'status'):
                # å¦‚æœè¿”å›çš„ä¸æ˜¯Responseå¯¹è±¡ï¼ŒåŒ…è£…æˆResponse
                return web.Response(text=str(response), headers=corscode)
            else:
                return response
        except web.HTTPException as ex:
            if ex.status == 404:
                return wj(
                    {
                        "code": ex.status,
                        "msg": f"æŸ¥è¯¢è¯·è®¿é—®http://{config.system.host}:{config.system.port}",
                    },
                    headers=corscode,
                )
            return wj({"code": ex.status, "msg": ex.reason}, headers=corscode)
        except Exception as e:
            logger.error(f"ä¸­é—´ä»¶å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {e}")
            return wj({"code": 500, "msg": str(e)}, headers=corscode)

    return middleware


# åˆ›å»ºä»»åŠ¡é˜Ÿåˆ—
async def create_task(taskname, data, request, searnum, apptype="web"):
    task = type('Task', (), {
        'curpro': 0,
        'numpro': len(data),
        'domains': [],
        'appname': apptype,
        'cancelled': False
    })()
    
    request.app["tasks"][taskname] = task

    async def process_app(appname, semaphore):
        async with semaphore:
            if task.cancelled:
                return
                
            error_retry_times = 0
            while error_retry_times < config.captcha.retry_times:
                if task.cancelled:
                    return
                    
                error_retry_times += 1
                proxy = None
                
                try:
                    # è·å–ä»£ç†é€»è¾‘
                    if config.proxy.local_ipv6_pool.enable:
                        proxy = ""
                    elif config.proxy.tunnel.url and is_valid_url(config.proxy.tunnel.url):
                        proxy = config.proxy.tunnel.url
                        logger.info(f"ä½¿ç”¨éš§é“ä»£ç†ï¼š{proxy}")
                    elif config.proxy.extra_api.url and is_valid_url(config.proxy.extra_api.url):
                        if config.proxy.extra_api.auto_maintenace:
                            proxy = await request.app.proxypool.getproxy()
                            logger.info(f"ä»æœ¬åœ°åœ°å€æ± è·å¾—ä»£ç†ï¼š{proxy}")
                        else:
                            timeout = aiohttp.ClientTimeout(total=config.system.http_client_timeout)
                            async with aiohttp.ClientSession(timeout=timeout) as session:
                                async with session.get(config.proxy.extra_api.url) as req:
                                    res = await req.text()
                                    proxy = f"http://{random.choice(res.split()).strip()}"
                            logger.info(f"ä»ä»£ç†æå–æ¥å£è·å¾—ä»£ç†ï¼š{proxy}")

                    # æ‰§è¡ŒæŸ¥è¯¢
                    data = await appth.get(apptype)(appname, proxy=proxy)

                    # å¤„ç†å“åº”
                    if data["code"] == 500:
                        if "è¯·æ±‚éªŒè¯ç æ—¶å¤±è´¥" in data.get("message", ''):
                            if proxy and proxy[7:] in pool_cache:
                                del pool_cache[proxy[7:]]
                                logger.info(f"ä»£ç†æ— æ•ˆï¼Œå·²å‰”é™¤ä»£ç†ï¼š{proxy[7:]}")

                        if data.get("message", "") == "å½“å‰è®¿é—®å·²è¢«åˆ›å®‡ç›¾æ‹¦æˆª":
                            logger.warning(f"å½“å‰è®¿é—®å·²è¢«åˆ›å®‡ç›¾æ‹¦æˆªï¼Œæ‰¹é‡ä»»åŠ¡ï¼š{taskname}ï¼Œä½¿ç”¨ä»£ç†ï¼š{proxy}")

                    if data["code"] == 200:
                        task.curpro += 1
                        # å¤„ç†è¿”å›æ•°æ®
                        if len(data["params"]["list"]) == 0:
                            if apptype == "web":
                                result_data = [{"contentTypeName": None, "domain": appname, "domainId": None, "leaderName": None,
                                         "limitAccess": None, "mainId": None, "mainLicence": None, "natureName": None,
                                         "serviceId": None, "serviceLicence": None, "unitName": None, "updateRecordTime": None}]
                            elif apptype in ["app", "mapp", "kapp"]:
                                result_data = [{"cityId": None, "countyId": None, "dataId": None, "leaderName": None,
                                         "mainId": None, "mainLicence": None, "mainUnitAddress": None, "mainUnitCertNo": None,
                                         "mainUnitCertType": None, "natureId": None, "natureName": None, "provinceId": None,
                                         "serviceId": None, "serviceLicence": None, "serviceName": appname, "serviceType": None,
                                         "unitName": None, "updateRecordTime": None, "version": None}]
                            else:
                                result_data = [{'blacklistLevel': None, 'serviceName': appname}]
                            task.domains.append(result_data)
                        else:
                            if apptype in ["bapp", "bweb", 'bkapp', 'bmapp']:
                                task.domains.append(data["params"])
                            else:
                                task.domains.append(data["params"]["list"])
                        break
                        
                except Exception as e:
                    logger.error(f"å¤„ç†ä»»åŠ¡ {appname} æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
                    
            if error_retry_times >= config.captcha.retry_times:
                logger.warning(f"ä»»åŠ¡ {appname} è¾¾åˆ°æœ€å¤§å°è¯•æ¬¡æ•° {config.captcha.retry_times}ï¼Œä»æœªæˆåŠŸå®Œæˆ")

    # ä½¿ç”¨ä¿¡å·é‡é™åˆ¶å¹¶å‘æ•°
    semaphore = asyncio.Semaphore(searnum)
    tasks = [process_app(appname, semaphore) for appname in data]
    
    try:
        await asyncio.gather(*tasks, return_exceptions=True)
    except Exception as e:
        logger.error(f"æ‰¹é‡ä»»åŠ¡ {taskname} æ‰§è¡Œå¤±è´¥: {e}")
    finally:
        # ä»»åŠ¡å®Œæˆåä¿å­˜ç»“æœåˆ°æ–‡ä»¶
        if taskname in request.app["tasks"]:
            task = request.app["tasks"][taskname]
            task.completed = True
            
            # åˆ›å»ºresultsç›®å½•
            import os
            results_dir = "batch_results"
            os.makedirs(results_dir, exist_ok=True)
            
            # ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶
            from datetime import datetime
            result_file = os.path.join(results_dir, f"{taskname}_{int(datetime.now().timestamp())}.json")
            
            try:
                import json
                with open(result_file, 'w', encoding='utf-8') as f:
                    result_data = {
                        'task_name': taskname,
                        'task_type': apptype,
                        'total_count': len(data),
                        'completed_count': task.curpro,
                        'result': task.domains
                    }
                    json.dump(result_data, f, ensure_ascii=False, indent=2)
                
                # æ›´æ–°æ•°æ®åº“
                db = request.app.get("db")
                if db:
                    success_count = sum(1 for item in task.domains if item and len(item) > 0)
                    db.update_batch_task(
                        taskname, 
                        completed_count=task.curpro,
                        success_count=success_count,
                        status='completed',
                        result_file=result_file,
                        finish_time=datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    )
                    logger.info(f"æ‰¹é‡ä»»åŠ¡ {taskname} å·²å®Œæˆï¼Œç»“æœå·²ä¿å­˜åˆ° {result_file}")
            except Exception as e:
                logger.error(f"ä¿å­˜ä»»åŠ¡ç»“æœå¤±è´¥: {e}")

# æŸ¥è¯¢ä»»åŠ¡è¿›åº¦
@jsondump
@routes.view(r"/query/task")
async def querytask(request):
    taskname = request.query.get("taskname")
    task = request.app["tasks"].get(taskname)
    if task is not None:
        return wj({
                "code": 200,
                "curpro": task.curpro,
                "numpro": task.numpro,
                "tasktype": task.appname,
                "progress": int(task.curpro / task.numpro * 100),
                "data":task.domains
            })
    else:
        return wj({
            "code":404,
            "message":"ä»»åŠ¡ä¸å­˜åœ¨"
        })


# åˆ›å»ºæ‰¹é‡æŸ¥è¯¢ä»»åŠ¡
@jsondump
@routes.view(r"/create/task")
async def create_task_catch(request):
    if request.method == "POST":
        data = await request.json()
        taskname = data.get("task")
        domains = data.get("data")
        seartype = data.get("type","web")

        if seartype not in config.risk_avoidance.allow_type:
            return wj({"code": 405,"message":"ä¸æ”¯æŒçš„æŸ¥è¯¢ç±»å‹"})
        
        if len(domains) == 0:
            return wj({"code":400,"message":"æäº¤çš„æŸ¥è¯¢åˆ—è¡¨ä¸ºç©º"})
        
        domains = [s for s in domains if not any(s.endswith(end) for end in config.risk_avoidance.prohibit_suffix)]

        if len(domains) == 0:
            return wj({"code":400,"message":"åœ¨å‰”é™¤ä¸å…è®¸æŸ¥è¯¢çš„å†…å®¹åï¼Œåˆ—è¡¨ä¸ºç©ºï¼Œå–æ¶ˆä»»åŠ¡"})
        
        searnum = int(data.get("searnum", 20))
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨åŒåä»»åŠ¡
        if taskname in request.app["tasks"]:
            return wj({"code": 409, "message": "ä»»åŠ¡å·²å­˜åœ¨"})
        
        # ä¿å­˜ä»»åŠ¡åˆ°æ•°æ®åº“
        db = request.app.get("db")
        if db:
            db.add_batch_task(taskname, seartype, len(domains))
        
        # åˆ›å»ºå¼‚æ­¥ä»»åŠ¡
        task_coroutine = create_task(taskname, domains, request, searnum, seartype)
        async_task = asyncio.create_task(task_coroutine)
        
        # æ·»åŠ ä»»åŠ¡åˆ°ç®¡ç†å™¨
        task_manager.add_task(taskname, async_task)
        
        logger.info(f"åˆ›å»ºæ‰¹é‡æŸ¥è¯¢ä»»åŠ¡ï¼š{taskname}")
        log_collector.add_log(f"åˆ›å»ºæ‰¹é‡æŸ¥è¯¢ä»»åŠ¡ï¼š{taskname}ï¼Œç±»å‹ï¼š{seartype}ï¼Œæ•°é‡ï¼š{len(domains)}")
        return wj({"code": 200,"message":"åˆ›å»ºä»»åŠ¡æˆåŠŸ"})

# åˆ é™¤æ‰¹é‡æŸ¥è¯¢ä»»åŠ¡
@jsondump
@routes.view(r"/delete/task")
async def del_task(request):
    if request.method == "POST":
        data = await request.json()
        taskname = data.get("task")
        
        if taskname in request.app["tasks"]:
            # æ ‡è®°ä»»åŠ¡ä¸ºå–æ¶ˆçŠ¶æ€
            task = request.app["tasks"][taskname]
            task.cancelled = True
            
            # ä»ä»»åŠ¡ç®¡ç†å™¨ä¸­ç§»é™¤
            task_manager.remove_task(taskname)
            
            # ä»åº”ç”¨ä»»åŠ¡å­—å…¸ä¸­åˆ é™¤
            del request.app["tasks"][taskname]
            
            logger.warning(f"åˆ é™¤æ‰¹é‡æŸ¥è¯¢ä»»åŠ¡ï¼š{taskname}")
            log_collector.add_log(f"åˆ é™¤æ‰¹é‡æŸ¥è¯¢ä»»åŠ¡ï¼š{taskname}")
            return wj({"code": 200})
        else:
            return wj({"code":404,"message":"ä»»åŠ¡ä¸å­˜åœ¨ï¼Œå¯èƒ½å·²ç»å®Œæˆæˆ–åˆ é™¤"})

@jsondump
@routes.view(r'/query/{path}')
async def geturl(request):
    path = request.match_info['path']

    if path not in appth and path not in bappth:
        return wj({"code":102,"msg":"ä¸æ˜¯æ”¯æŒçš„æŸ¥è¯¢ç±»å‹"})

    if path not in config.risk_avoidance.allow_type:
        return wj({"code":102,"msg":"ä¸æ˜¯æ”¯æŒçš„æŸ¥è¯¢ç±»å‹"})
    
    if request.method == "GET":
        appname = request.query.get("search")
        pageNum = request.query.get("pageNum")
        pageSize = request.query.get("pageSize")
        proxy = request.query.get("proxy")
        
    if request.method == "POST":
        data = await request.json()
        appname = data.get("search")
        pageNum = data.get("pageNum")
        pageSize = data.get("pageSize")
        proxy = data.get("proxy")

    if not not any(appname.endswith(suffix) for suffix in config.risk_avoidance.prohibit_suffix):
        return wj({"code": 405,"message":"ä¸å…è®¸çš„æŸ¥è¯¢å†…å®¹"})

    if not appname:
        return wj({"code":101,"msg":"å‚æ•°é”™è¯¯,è¯·æŒ‡å®šsearchå‚æ•°"})
    
    if proxy is not None:
        logger.info(f"ä½¿ç”¨æŒ‡å®šä»£ç†ï¼š{proxy}")
        for i in range(config.captcha.retry_times):
            data = await appth.get(path)(appname, pageNum, pageSize, proxy=f"http://{proxy}")
            if data.get("code", 500) == 200:
                return wj(data)
            if data.get("message", "") == "å½“å‰è®¿é—®å·²è¢«åˆ›å®‡ç›¾æ‹¦æˆª":
                logger.warning("å½“å‰è®¿é—®å·²è¢«åˆ›å®‡ç›¾æ‹¦æˆª")
                return wj(data)
        return wj(data)

    for i in range(config.captcha.retry_times):
        proxy = None
        if config.proxy.local_ipv6_pool.enable:
            proxy = ""

        elif not proxy and config.proxy.tunnel.url:
            if is_valid_url(config.proxy.tunnel.url):
                proxy = config.proxy.tunnel.url
                logger.info(f"ä½¿ç”¨éš§é“ä»£ç†ï¼š{proxy}")
            else:
                logger.error(f"å½“å‰å¯ç”¨éš§é“ä»£ç†ï¼Œä½†ä»£ç†åœ°å€æ— æ•ˆï¼š{config.proxy.tunnel.url}")
                return wj({"code":500,"message":"å½“å‰å¯ç”¨éš§é“ä»£ç†ï¼Œä½†ä»£ç†åœ°å€æ— æ•ˆ"})

        elif not proxy and config.proxy.extra_api.url:
            if is_valid_url(config.proxy.extra_api.url):
                if config.proxy.extra_api.auto_maintenace:
                    proxy = await request.app.proxypool.getproxy()
                    logger.info(f"ä»æœ¬åœ°åœ°å€æ± è·å¾—ä»£ç†ï¼š{proxy}")
                else:
                    timeout = aiohttp.ClientTimeout(total=config.system.http_client_timeout)
                    async with aiohttp.ClientSession(timeout=timeout) as session:
                        async with session.get(config.proxy.extra_api.url) as req:
                            res = await req.text()
                            proxy = f"http://{random.choice(res.split()).strip()}"
                    logger.info(f"ä»ä»£ç†æå–æ¥å£è·å¾—ä»£ç†ï¼š{proxy}")
            else:
                logger.error(f"å½“å‰å¯ç”¨APIæå–ä»£ç†ï¼Œä½†APIåœ°å€æ— æ•ˆï¼š{config.proxy.extra_api.url}")
                return wj({"code":500,"message":"å½“å‰å¯ç”¨APIæå–ä»£ç†ï¼Œä½†APIåœ°å€æ— æ•ˆ"})
        if path in appth:
            data = await appth.get(path)(appname, pageNum, pageSize, proxy=proxy)
        else:
            data = await bappth.get(path)(appname, proxy=proxy)

        if data.get("code", 500) == 200:
            # ä¿å­˜å†å²è®°å½•
            db = request.app.get("db")
            if db:
                result_count = len(data.get("params", {}).get("list", [])) if path in appth else len(data.get("params", []))
                db.add_history(path, appname, result_count, data.get("params"))
            return wj(data)
        if data.get("message", "") == "å½“å‰è®¿é—®å·²è¢«åˆ›å®‡ç›¾æ‹¦æˆª":
            logger.warning("å½“å‰è®¿é—®å·²è¢«åˆ›å®‡ç›¾æ‹¦æˆª")
            return wj(data)
    return wj(data)

# å†å²è®°å½•ç›¸å…³è·¯ç”±
@jsondump
@routes.view(r"/history")
async def get_history(request):
    """è·å–å†å²è®°å½•åˆ—è¡¨"""
    limit = int(request.query.get("limit", 50))
    offset = int(request.query.get("offset", 0))
    search_type = request.query.get("type")
    
    db = request.app.get("db")
    if not db:
        return wj({"code": 500, "message": "æ•°æ®åº“æœªåˆå§‹åŒ–"})
    
    history_list = db.get_history(limit=limit, offset=offset, search_type=search_type)
    total_count = db.get_history_count(search_type=search_type)
    
    return wj({
        "code": 200,
        "data": history_list,
        "total": total_count,
        "limit": limit,
        "offset": offset
    })

@jsondump
@routes.view(r"/history/{history_id:\d+}")
async def get_history_detail(request):
    """è·å–å†å²è®°å½•è¯¦æƒ…"""
    history_id = int(request.match_info['history_id'])
    
    db = request.app.get("db")
    if not db:
        return wj({"code": 500, "message": "æ•°æ®åº“æœªåˆå§‹åŒ–"})
    
    history_detail = db.get_history_detail(history_id)
    
    if history_detail:
        return wj({"code": 200, "data": history_detail})
    else:
        return wj({"code": 404, "message": "å†å²è®°å½•ä¸å­˜åœ¨"})

@jsondump
@routes.view(r"/history/delete/{history_id:\d+}")
async def delete_history(request):
    """åˆ é™¤å†å²è®°å½•"""
    history_id = int(request.match_info['history_id'])
    
    db = request.app.get("db")
    if not db:
        return wj({"code": 500, "message": "æ•°æ®åº“æœªåˆå§‹åŒ–"})
    
    success = db.delete_history(history_id)
    
    if success:
        return wj({"code": 200, "message": "åˆ é™¤æˆåŠŸ"})
    else:
        return wj({"code": 500, "message": "åˆ é™¤å¤±è´¥"})

@jsondump
@routes.view(r"/history/clear")
async def clear_history(request):
    """æ¸…ç©ºå†å²è®°å½•"""
    if request.method == "POST":
        data = await request.json()
        search_type = data.get("type")
        
        db = request.app.get("db")
        if not db:
            return wj({"code": 500, "message": "æ•°æ®åº“æœªåˆå§‹åŒ–"})
        
        success = db.clear_history(search_type=search_type)
        
        if success:
            return wj({"code": 200, "message": "æ¸…ç©ºæˆåŠŸ"})
        else:
            return wj({"code": 500, "message": "æ¸…ç©ºå¤±è´¥"})

# æ‰¹é‡ä»»åŠ¡ç®¡ç†ç›¸å…³è·¯ç”±
@routes.view(r"/batch/tasks")
async def get_batch_tasks(request):
    """è·å–æ‰¹é‡ä»»åŠ¡åˆ—è¡¨"""
    try:
        db = request.app.get("db")
        if not db:
            return {"code": 500, "message": "æ•°æ®åº“æœªåˆå§‹åŒ–"}
        
        limit = int(request.query.get("limit", 20))
        offset = int(request.query.get("offset", 0))
        status = request.query.get("status", "")
        
        tasks = db.get_batch_tasks(limit=limit, offset=offset, status=status if status else None)
        total = db.get_batch_tasks_count(status=status if status else None)
        
        return wj({"code": 200, "data": tasks, "total": total})
    except Exception as e:
        logger.error(f"è·å–æ‰¹é‡ä»»åŠ¡åˆ—è¡¨å¤±è´¥: {e}")
        return wj({"code": 500, "message": f"è·å–ä»»åŠ¡åˆ—è¡¨å¤±è´¥: {str(e)}"})

@routes.view(r"/batch/task/{task_name}")
async def get_batch_task_detail(request):
    """è·å–æ‰¹é‡ä»»åŠ¡è¯¦æƒ…"""
    try:
        task_name = request.match_info.get("task_name")
        
        db = request.app.get("db")
        if not db:
            return wj({"code": 500, "message": "æ•°æ®åº“æœªåˆå§‹åŒ–"})
        
        task = db.get_batch_task_detail(task_name)
        
        if task:
            # å¦‚æœä»»åŠ¡å·²å®Œæˆä¸”æœ‰ç»“æœæ–‡ä»¶ï¼Œè¯»å–ç»“æœ
            if task.get('result_file') and os.path.exists(task['result_file']):
                try:
                    import json
                    with open(task['result_file'], 'r', encoding='utf-8') as f:
                        result_data = json.load(f)
                        task['result_data'] = result_data
                except Exception as e:
                    logger.error(f"è¯»å–ç»“æœæ–‡ä»¶å¤±è´¥: {e}")
            
            return wj({"code": 200, "data": task})
        else:
            return wj({"code": 404, "message": "ä»»åŠ¡ä¸å­˜åœ¨"})
    except Exception as e:
        logger.error(f"è·å–æ‰¹é‡ä»»åŠ¡è¯¦æƒ…å¤±è´¥: {e}")
        return wj({"code": 500, "message": f"è·å–ä»»åŠ¡è¯¦æƒ…å¤±è´¥: {str(e)}"})

@routes.view(r"/batch/task/delete/{task_name}")
async def delete_batch_task_api(request):
    """åˆ é™¤æ‰¹é‡ä»»åŠ¡"""
    try:
        task_name = request.match_info.get("task_name")
        
        db = request.app.get("db")
        if not db:
            return wj({"code": 500, "message": "æ•°æ®åº“æœªåˆå§‹åŒ–"})
        
        success = db.delete_batch_task(task_name)
        
        if success:
            return wj({"code": 200, "message": "åˆ é™¤æˆåŠŸ"})
        else:
            return wj({"code": 500, "message": "åˆ é™¤å¤±è´¥"})
    except Exception as e:
        logger.error(f"åˆ é™¤æ‰¹é‡ä»»åŠ¡å¤±è´¥: {e}")
        return wj({"code": 500, "message": f"åˆ é™¤ä»»åŠ¡å¤±è´¥: {str(e)}"})

# é…ç½®ç®¡ç†ç›¸å…³è·¯ç”±
@jsondump
@routes.view(r"/config")
async def get_config(request):
    """è·å–é…ç½®ä¿¡æ¯"""
    try:
        config_data = {
            "system": {
                "host": config.system.host,
                "port": config.system.port,
                "http_client_timeout": config.system.http_client_timeout,
                "web_ui": config.system.web_ui,
                "detail_concurrency": config.system.detail_concurrency
            },
            "captcha": {
                "enable": config.captcha.enable,
                "save_failed_img": config.captcha.save_failed_img,
                "save_failed_img_path": config.captcha.save_failed_img_path,
                "device": config.captcha.device,
                "retry_times": config.captcha.retry_times,
                "coding_code": config.captcha.coding_code,
                "coding_show": config.captcha.coding_show
            },
            "proxy": {
                "local_ipv6_pool": {
                    "enable": config.proxy.local_ipv6_pool.enable,
                    "pool_num": config.proxy.local_ipv6_pool.pool_num,
                    "check_interval": config.proxy.local_ipv6_pool.check_interval,
                    "ipv6_network_card": config.proxy.local_ipv6_pool.ipv6_network_card
                },
                "tunnel": {
                    "url": config.proxy.tunnel.url or ""
                },
                "extra_api": {
                    "url": config.proxy.extra_api.url or "",
                    "extra_interval": config.proxy.extra_api.extra_interval,
                    "timeout": config.proxy.extra_api.timeout,
                    "timeout_drop": config.proxy.extra_api.timeout_drop,
                    "check_proxy": config.proxy.extra_api.check_proxy,
                    "proxy_timeout": config.proxy.extra_api.proxy_timeout,
                    "check_proxy_num": config.proxy.extra_api.check_proxy_num,
                    "auto_maintenace": config.proxy.extra_api.auto_maintenace,
                    "pool_num": config.proxy.extra_api.pool_num
                }
            },
            "log": {
                "dir": config.log.dir,
                "file_head": config.log.file_head,
                "backup_count": config.log.backup_count,
                "save_log": config.log.save_log,
                "output_console": config.log.output_console
            }
        }
        return wj({"code": 200, "data": config_data})
    except Exception as e:
        logger.error(f"è¯»å–é…ç½®å¤±è´¥: {e}")
        return wj({"code": 500, "message": f"è¯»å–é…ç½®å¤±è´¥: {str(e)}"})

@jsondump
@routes.view(r"/config/save")
async def save_config(request):
    """ä¿å­˜é…ç½®"""
    if request.method == "POST":
        try:
            import yaml
            data = await request.json()
            
            # æ„å»ºé…ç½®å­—å…¸
            config_dict = {
                "system": {
                    "host": data.get("system", {}).get("host", "0.0.0.0"),
                    "port": int(data.get("system", {}).get("port", 16181)),
                    "http_client_timeout": int(data.get("system", {}).get("http_client_timeout", 5)),
                    "web_ui": bool(data.get("system", {}).get("web_ui", True)),
                    "detail_concurrency": int(data.get("system", {}).get("detail_concurrency", 5))
                },
                "captcha": {
                    "enable": bool(data.get("captcha", {}).get("enable", True)),
                    "save_failed_img": bool(data.get("captcha", {}).get("save_failed_img", False)),
                    "save_failed_img_path": data.get("captcha", {}).get("save_failed_img_path", "faile_captcha"),
                    "device": data.get("captcha", {}).get("device", ["CPU"]),
                    "retry_times": int(data.get("captcha", {}).get("retry_times", 2)),
                    "coding_code": data.get("captcha", {}).get("coding_code", "auto"),
                    "coding_show": bool(data.get("captcha", {}).get("coding_show", False))
                },
                "proxy": {
                    "local_ipv6_pool": {
                        "enable": bool(data.get("proxy", {}).get("local_ipv6_pool", {}).get("enable", False)),
                        "pool_num": int(data.get("proxy", {}).get("local_ipv6_pool", {}).get("pool_num", 88)),
                        "check_interval": int(data.get("proxy", {}).get("local_ipv6_pool", {}).get("check_interval", 1)),
                        "ipv6_network_card": data.get("proxy", {}).get("local_ipv6_pool", {}).get("ipv6_network_card", "eth0")
                    },
                    "tunnel": {
                        "url": data.get("proxy", {}).get("tunnel", {}).get("url") or None
                    },
                    "extra_api": {
                        "url": data.get("proxy", {}).get("extra_api", {}).get("url") or None,
                        "extra_interval": int(data.get("proxy", {}).get("extra_api", {}).get("extra_interval", 3)),
                        "timeout": int(data.get("proxy", {}).get("extra_api", {}).get("timeout", 100)),
                        "timeout_drop": int(data.get("proxy", {}).get("extra_api", {}).get("timeout_drop", 8)),
                        "check_proxy": bool(data.get("proxy", {}).get("extra_api", {}).get("check_proxy", True)),
                        "proxy_timeout": float(data.get("proxy", {}).get("extra_api", {}).get("proxy_timeout", 0.5)),
                        "check_proxy_num": int(data.get("proxy", {}).get("extra_api", {}).get("check_proxy_num", 20)),
                        "auto_maintenace": bool(data.get("proxy", {}).get("extra_api", {}).get("auto_maintenace", True)),
                        "pool_num": int(data.get("proxy", {}).get("extra_api", {}).get("pool_num", 100))
                    }
                },
                "risk_avoidance": {
                    "allow_type": ["web", "app", "mapp", "kapp", "bweb", "bapp", "bmapp", "bkapp"],
                    "prohibit_suffix": []
                },
                "log": {
                    "dir": data.get("log", {}).get("dir", "logs"),
                    "file_head": data.get("log", {}).get("file_head", "ymicp"),
                    "backup_count": int(data.get("log", {}).get("backup_count", 7)),
                    "save_log": bool(data.get("log", {}).get("save_log", False)),
                    "output_console": bool(data.get("log", {}).get("output_console", True))
                }
            }
            
            # å¤‡ä»½åŸé…ç½®æ–‡ä»¶
            config_path = get_resource_path("config.yml")
            backup_path = get_resource_path("config.yml.backup")
            
            import shutil
            if os.path.exists(config_path):
                shutil.copy(config_path, backup_path)
            
            # ä¿å­˜æ–°é…ç½®
            with open(config_path, 'w', encoding='utf-8') as f:
                yaml.dump(config_dict, f, allow_unicode=True, default_flow_style=False, sort_keys=False)
            
            logger.info("é…ç½®æ–‡ä»¶å·²æ›´æ–°ï¼Œéœ€è¦é‡å¯æœåŠ¡ç”Ÿæ•ˆ")
            log_collector.add_log("é…ç½®æ–‡ä»¶å·²æ›´æ–°ï¼Œéœ€è¦é‡å¯æœåŠ¡ç”Ÿæ•ˆ")
            return wj({"code": 200, "message": "é…ç½®ä¿å­˜æˆåŠŸï¼Œé‡å¯æœåŠ¡åç”Ÿæ•ˆ"})
        except Exception as e:
            logger.error(f"ä¿å­˜é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            return wj({"code": 500, "message": f"ä¿å­˜é…ç½®å¤±è´¥: {str(e)}"})

# æ—¥å¿—ç®¡ç†ç›¸å…³è·¯ç”±
@jsondump
@routes.view(r"/logs/realtime")
async def get_realtime_logs(request):
    """è·å–å®æ—¶æ—¥å¿—"""
    limit = int(request.query.get('limit', 500))
    
    try:
        logs = log_collector.get_logs(limit)
        return wj({"code": 200, "data": logs, "total": len(logs)})
    except Exception as e:
        logger.error(f"è·å–å®æ—¶æ—¥å¿—å¤±è´¥: {e}")
        return wj({"code": 500, "message": f"è·å–å®æ—¶æ—¥å¿—å¤±è´¥: {str(e)}"})

@jsondump
@routes.view(r"/logs/clear")
async def clear_logs(request):
    """æ¸…ç©ºå®æ—¶æ—¥å¿—"""
    try:
        log_collector.clear()
        return wj({"code": 200, "message": "æ—¥å¿—å·²æ¸…ç©º"})
    except Exception as e:
        return wj({"code": 500, "message": f"æ¸…ç©ºæ—¥å¿—å¤±è´¥: {str(e)}"})

if config.system.web_ui:
    @routes.view(r"/")
    async def index(request):
        response = aiohttp_jinja2.render_template("index.html", request, {})
        return response

async def init_proxy_pool(app):
    if not hasattr(app, "proxypool"):
        app.proxypool = Pool()
        await app.proxypool.start()
        logger.info("åˆå§‹åŒ–åœ°å€æ± ç»´æŠ¤ä»»åŠ¡")

async def cleanup_proxy_pool(app):
    if hasattr(app, "proxypool"):
        await app.proxypool.stop()
        logger.info("æ¸…ç†åœ°å€æ± ç»´æŠ¤ä»»åŠ¡")

if __name__ == "__main__":

    myicp = beian()
    appth = {
        "web": myicp.ymWeb,  # ç½‘ç«™
        "app": myicp.ymApp,  # APP
        "mapp": myicp.ymMiniApp,  # å°ç¨‹åº
        "kapp": myicp.ymKuaiApp,  # å¿«åº”ç”¨
    }

    # è¿æ³•è¿è§„åº”ç”¨ä¸æ”¯æŒç¿»é¡µ
    bappth = {
        "bweb": myicp.bymWeb,  # è¿æ³•è¿è§„ç½‘ç«™
        "bapp": myicp.bymApp,  # è¿æ³•è¿è§„APP
        "bmapp": myicp.bymMiniApp,  # è¿æ³•è¿è§„å°ç¨‹åº
        "bkapp": myicp.bymKuaiApp,  # è¿æ³•è¿è§„å¿«åº”ç”¨
    }

    app = web.Application()

    if config.proxy.local_ipv6_pool.enable:
        app.on_startup.append(init_ipv6_pool)
    elif config.proxy.tunnel.url is None:
        if config.proxy.extra_api.url is not None:
            if is_valid_url(config.proxy.extra_api.url):
                if config.proxy.extra_api.auto_maintenace:
                    logger.info("è‡ªåŠ¨ç»´æŠ¤æœ¬åœ°åœ°å€æ± "
                            f"æå–é—´éš”ï¼š{config.proxy.extra_api.extra_interval}ç§’ ï¼Œ"
                            f"è¶…æ—¶æ—¶é—´ï¼š{config.proxy.extra_api.timeout} ç§’ ï¼Œ"
                            f"æå‰ä¸¢å¼ƒï¼š{config.proxy.extra_api.timeout_drop} ç§’ ")
                    app.on_startup.append(init_proxy_pool)
                    app.on_cleanup.append(cleanup_proxy_pool)
            else:
                logger.warning("å½“å‰å¯ç”¨äº†APIæå–ä»£ç†ï¼Œä½†è¯¥åœ°å€ä¼¼ä¹æ— æ•ˆï¼Œå°†ä¸ä½¿ç”¨è¯¥ä»£ç†")

    aiohttp_jinja2.setup(app, loader=jinja2.FileSystemLoader(get_resource_path("templates")))
    app.add_routes(routes)
    app["tasks"] = {}
    
    # åˆå§‹åŒ–æ•°æ®åº“
    app["db"] = Database()

    print('''
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ                      ğŸ—ï¸  èµåŠ©å•†                           â”ƒ
â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â˜ï¸  æ—æ«äº‘                                               â”‚
â”‚  â”œâ”€ ä¼ä¸šçº§ä¸šåŠ¡äº‘ã€ä¸“ä¸šé«˜é¢‘æ¸¸æˆäº‘æä¾›å•†                   â”‚
â”‚  â””â”€ ğŸŒ https://www.dkdun.cn                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸš€  ANT PING                                            â”‚
â”‚  â”œâ”€ ä¸€ç«™å¼ç½‘ç»œæ£€æµ‹å·¥å…·                                   â”‚
â”‚  â””â”€ ğŸŒ https://antping.com                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
''')
    
    app.middlewares.append(options_middleware)
    if config.system.web_ui:
        print(f"\nweb ui: http://{'127.0.0.1' if config.system.host == '0.0.0.0' else config.system.host}:{config.system.port}\n\n"
              "æŒ‰ä¸¤æ¬¡ Ctrl + C å¯ä»¥é€€å‡ºç¨‹åº\n")
    
    # å°†LogCollectorå¤„ç†å™¨æ·»åŠ åˆ°root logger
    collector_handler = CollectorHandler(log_collector)
    collector_handler.setLevel(logging.INFO)
    formatter = logging.Formatter('[%(asctime)s] %(levelname)s - %(message)s', '%Y-%m-%d %H:%M:%S')
    collector_handler.setFormatter(formatter)
    logging.getLogger().addHandler(collector_handler)
    
    # å¯åŠ¨æ—¶æ·»åŠ æ—¥å¿—
    logger.info(f"æœåŠ¡å¯åŠ¨ - ç›‘å¬åœ°å€: {config.system.host}:{config.system.port}")
    logger.info(f"éªŒè¯ç è¯†åˆ«: {'å¯ç”¨' if config.captcha.enable else 'ç¦ç”¨'}")
    
    web.run_app(app, host=config.system.host, port=config.system.port)
